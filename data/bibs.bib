
// ========== Image compression ==========
// ==========       BEGIN       ==========

@article{agustsson_generative_2019,
  title  = {Generative {Adversarial} {Networks} for {Extreme} {Learned} {Image} {Compression}},
  author = {Agustsson, Eirikur and Tschannen, Michael and Mentzer, Fabian and Timofte, Radu and Van Gool, Luc},
  year   = {2019}
}
@article{ronneberger_u-net_2015,
  address   = {Cham},
  title     = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
  booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  year      = {2015}
}
@article{dumoulin_adversarially_2017,
  title  = {Adversarially {Learned} {Inference}},
  author = {Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Mastropietro, Olivier and Lamb, Alex and Arjovsky, Martin and Courville, Aaron},
  year   = {2017}
}
@article{donahue_adversarial_2017,
  title    = {Adversarial {Feature} {Learning}},
  abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
  author   = {Donahue, Jeff and Krähenbühl, Philipp and Darrell, Trevor},
  year     = {2017}
}
@article{salimans_improved_2016,
  title     = {Improved {Techniques} for {Training} {GANs}},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  author    = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
  year      = {2016}
}
@article{radford_unsupervised_2016,
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  year   = {2015},
  title  = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}
}
@article{odena_deconvolution_2016,
  title   = {Deconvolution and {Checkerboard} {Artifacts}},
  journal = {Distill},
  author  = {Odena, Augustus and Dumoulin, Vincent and Olah, Chris},
  year    = {2016}
}
@article{shi_real-time_2016,
  author = {Shi, Wenzhe and Caballero, Jose and Huszár, Ferenc and Totz, Johannes and Aitken, Andrew and Bishop, Rob and Rueckert, Daniel and Wang, Zehan},
  year   = {2016},
  title  = {Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network}
}
@article{theis_lossy_2017,
  title    = {Lossy {Image} {Compression} with {Compressive} {Autoencoders}},
  abstract = {We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.},
  author   = {Theis, Lucas and Shi, Wenzhe and Cunningham, Andrew and Huszár, Ferenc},
  year     = {2017}
}
@article{li_learning_2020,
  title   = {Learning a {Single} {Model} with a {Wide} {Range} of {Quality} {Factors} for {JPEG} {Image} {Artifacts} {Removal}},
  journal = {IEEE Transactions on Image Processing},
  author  = {Li, Jianwei and Wang, Yongtao and Xie, Haihua and Ma, Kai-Kuang},
  year    = {2020}
}
@article{wallace_jpeg_1992,
  title   = {The {JPEG} still picture compression standard},
  journal = {IEEE Transactions on Consumer Electronics},
  author  = {Wallace, G.K.},
  year    = {1992}
}
@article{ehrlich_quantization_2020,
  title     = {Quantization {Guided} {JPEG} {Artifact} {Correction}},
  booktitle = {Computer {Vision} – {ECCV} 2020},
  author    = {Ehrlich, Max and Davis, Larry and Lim, Ser-Nam and Shrivastava, Abhinav},
  year      = {2020}
}
@article{jiang_towards_2021,
  title     = {Towards Flexible Blind JPEG Artifacts Removal},
  author    = {Jiang, Jiaxi and Zhang, Kai and Timofte, Radu},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year      = {2021}
}
@misc{noauthor_clic_nodate,
  title = {{CLIC} · {Challenge} on {Learned} {Image} {Compression}},
  url   = {http://compression.cc/},
  file  = {CLIC · Challenge on Learned Image Compression:C\:\\Users\\nadol\\Zotero\\storage\\RB4DJCRX\\compression.cc.html:text/html}
}
@techreport{kingma_adam_2017,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  booktitle = {ICLR (Poster)}
}

// ========== Image compression ==========
// ==========        END        ==========

@inproceedings{yang_graph_2018,
  address   = {Cham},
  title     = {Graph {R}-{CNN} for {Scene} {Graph} {Generation}},
  booktitle = {Computer {Vision} – {ECCV} 2018},
  author    = {Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  year      = {2018}
}
@article{toderici_full_2017,
  title  = {Full {Resolution} {Image} {Compression} with {Recurrent} {Neural} {Networks}},
  author = {Toderici, George and Vincent, Damien and Johnston, Nick and Hwang, Sung Jin and Minnen, David and Shor, Joel and Covell, Michele},
  year   = {2017}
}
@inproceedings{zhang2017learning,
  title     = {Learning Deep CNN Denoiser Prior for Image Restoration},
  author    = {Zhang, Kai and Zuo, Wangmeng and Gu, Shuhang and Zhang, Lei},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2017}
}
@article{zhang2020plug,
  title  = {Plug-and-Play Image Restoration with Deep Denoiser Prior},
  author = {Zhang, Kai and Li, Yawei and Zuo, Wangmeng and Zhang, Lei and Van Gool, Luc and Timofte, Radu},
  year   = {2020}
}
@article{Autoencoder_2006,
  author  = {Geoffrey Hinton and Ruslan Salakhutdinov},
  title   = {Reducing the Dimensionality of Data with Neural Networks},
  journal = {Science},
  year    = {2006}
}
@misc{autoencoder_papers,
  title    = {Papers with {Code} - {AutoEncoder} {Explained}},
  url      = {https://paperswithcode.com/method/autoencoder},
  abstract = {An Autoencoder is a bottleneck architecture that turns a high-dimensional input into a latent low-dimensional code (encoder), and then performs a reconstruction of the input with this latent code (the decoder). Image: Michael Massi}
}
@article{mentzer_high_fidelity_2020,
  title     = {High-{Fidelity} {Generative} {Image} {Compression}},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  author    = {Mentzer, Fabian and Toderici, George D and Tschannen, Michael and Agustsson, Eirikur},
  year      = {2020}
}
@article{JPEG-1992,
  title   = {The JPEG still picture compression standard},
  journal = {IEEE Transactions on Consumer Electronics},
  author  = {Wallace, G.K.},
  year    = {1992}
}
@article{Huffman-Coding,
  author  = {Huffman, David A.},
  journal = {Proceedings of the IRE},
  title   = {A Method for the Construction of Minimum-Redundancy Codes},
  year    = {1952}
}
@article{Arithmetic-Coding,
  author  = {Witten, Ian H. and Neal, Radford M. and Cleary, John G.},
  title   = {Arithmetic Coding for Data Compression},
  year    = {1987},
  journal = {Commun. ACM}
}
@article{pca,
  author  = { Karl   Pearson   F.R.S. },
  title   = {LIII. On lines and planes of closest fit to systems of points in space},
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  year    = {1901}
}
@article{balle_variational_2018,
  title     = {Variational image compression with a scale hyperprior},
  author    = {Johannes Ballé and David Minnen and Saurabh Singh and Sung Jin Hwang and Nick Johnston},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}
@article{krishna_visual_2017,
  title   = {Visual {Genome}: {Connecting} {Language} and {Vision} {Using} {Crowdsourced} {Dense} {Image} {Annotations}},
  journal = {International Journal of Computer Vision},
  author  = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
  year    = {2017},
  pages   = {32-73}
}
@article{Zhao_Meng_Yin_Sigal_2019,
  title  = {Image Generation from Layout},
  author = {Zhao, Bo and Meng, Lili and Yin, Weidong and Sigal, Leonid},
  year   = {2019}
}
@article{Balle_Laparra_Simoncelli_2017,
  author  = {Cai, Chunlei and Chen, Li and Zhang, Xiaoyun and Gao, Zhiyong},
  journal = {IEEE Transactions on Image Processing},
  title   = {End-to-End Optimized ROI Image Compression},
  year    = {2020},
  volume  = {29},
  pages   = {3442-3457}
}
@article{Toderici_Vincent_Johnston_Hwang_Minnen_Shor_Covell_2017,
  author    = {Toderici, George and Vincent, Damien and Johnston, Nick and Hwang, Sung Jin and Minnen, David and Shor, Joel and Covell, Michele},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Full Resolution Image Compression with Recurrent Neural Networks},
  year      = {2017},
  pages     = {5435-5443}
}
@article{Goodfellow_Pouget-Abadie_Mirza_Xu_Warde-Farley_Ozair_Courville_Bengio_2014,
  title        = {Generative Adversarial Networks},
  abstractnote = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  author       = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year         = {2014}
}
@misc{kodak,
  title = {True {Color} {Kodak} {Images}},
  fil   = {http://r0k.us/graphics/kodak/}
}
@article{OpenImages2,
  title   = {OpenImages: A public dataset for large-scale multi-label and multi-class image classification.},
  author  = {Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and Abu-El-Haija, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Kamali, Shahab and Malloci, Matteo and Pont-Tuset, Jordi and Veit, Andreas and Belongie, Serge and Gomes, Victor and Gupta, Abhinav and Sun, Chen and Chechik, Gal and Cai, David and Feng, Zheyun and Narayanan, Dhyanesh and Murphy, Kevin},
  journal = {Dataset available from https://storage.googleapis.com/openimages/web/index.html},
  year    = {2017}
}
@inbook{Wang_Yu_Wu_Gu_Liu_Dong_Qiao_Loy_2019,
  series     = {Lecture Notes in Computer Science},
  title      = {ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks},
  booktitle  = {Computer Vision – ECCV 2018 Workshops},
  publisher  = {Springer International Publishing},
  author     = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Qiao, Yu and Loy, Chen Change},
  year       = {2019},
  pages      = {63–79},
  collection = {Lecture Notes in Computer Science}
}
@article{schonfeld_u-net_2021,
  author    = {Schönfeld, Edgar and Schiele, Bernt and Khoreva, Anna},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {A U-Net Based Discriminator for Generative Adversarial Networks},
  year      = {2020},
  pages     = {8204-8213}
}
@article{Wang_Xie_Dong_Shan_2021,
  author    = {Wang, Xintao and Xie, Liangbin and Dong, Chao and Shan, Ying},
  booktitle = {2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)},
  title     = {Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data},
  year      = {2021},
  pages     = {1905-1914}
}
@article{Ledig_Theis_Huszar_Caballero_Cunningham_Acosta_Aitken_Tejani_Totz_Wang_et_al_2017,
  author    = {Ledig, Christian and Theis, Lucas and Huszár, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
  year      = {2017},
  pages     = {105-114}
}
@article{fcn,
  author    = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Fully convolutional networks for semantic segmentation},
  year      = {2015},
  pages     = {3431-3440}
}
@article{simonyan_very_2015,
  author    = {Liu, Shuying and Deng, Weihong},
  booktitle = {2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)},
  title     = {Very deep convolutional neural network based image classification using small training sample size},
  year      = {2015},
  pages     = {730-734}
}
@article{alexnet,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  year      = {2017},
  publisher = {Association for Computing Machinery},
  volume    = {60},
  number    = {6},
  journal   = {Commun. ACM},
  pages     = {84–90}
}
@inproceedings{yang_graph_2018,
  address   = {Cham},
  title     = {Graph {R}-{CNN} for {Scene} {Graph} {Generation}},
  booktitle = {Computer {Vision} – {ECCV} 2018},
  publisher = {Springer International Publishing},
  author    = {Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  year      = {2018},
  pages     = {690-706}
}
@article{adgrad,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121-2159}
}
@article{adadelta,
  author  = {Zeiler, Matthew D.},
  journal = {CoRR},
  title   = {ADADELTA: An Adaptive Learning Rate Method},
  year    = 2012
}
@article{conditional_gans,
  author    = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title     = {High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs},
  year      = {2018},
  pages     = {8798-8807}
}
@article{batch_norm,
  author  = {Sergey Ioffe and Christian Szegedy},
  title   = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  journal = {CoRR},
  year    = {2015}
}
@article{layer_norm,
  author   = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title    = {Layer Normalization},
  journal  = {arXiv},
  year     = {2016}
}
@article{instance_norm,
  author  = {Dmitry Ulyanov and Andrea Vedaldi and Victor S. Lempitsky},
  title   = {Instance Normalization: The Missing Ingredient for Fast Stylization},
  journal = {CoRR},
  volume  = {abs/1607.08022},
  year    = {2016}
}